{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teoremas Asintóticos\n",
    "\n",
    "## Ley débil de los grandes números\n",
    "<span style=\"color:#0066CC\">Before, we saw the frequentist interpretation of probability:</span>\n",
    "- Sea $n$ el número de experimentos, y $n(A)$ el número de veces que el evento $A$ ocurre en la realización de esos experimentos, entonces $P(A) = \\frac{n(A)}{n}$. \n",
    "\n",
    "<span style=\"color:#0066CC\">Por qué podemos obtener probabilidad así? </span>\n",
    "\n",
    "<span style=\"color:#0066CC\">**The law of large numbers** provides the proof. It links the abstract concept of probability and frequency. This theorem says that the mean of a large sample is close to the mean of the distribution. </span>\n",
    "\n",
    "<span style=\"color:#0066CC\">(Rewrote the therom in a simplier form)</span>\n",
    "\n",
    "<span style=\"color:#0066CC\">Sean $X_1,...X_n$ v.a. independientes idénticamente distribuidas (iid) de media $\\mu$. Entonces, para cualquier $\\epsilon >0$, $\\overline{X}_n=\\frac{1}{n}\\sum_{i=1}^n X_i$ cumple:</span>\n",
    "\n",
    "$$\\lim_{n \\to \\infty} P\\left\\{\\middle | \\overline{X}_n - \\mu \\,\\middle | > \\epsilon \\right\\} = 0$$\n",
    "\n",
    "<span style=\"color:#0066CC\">Es decir, the distribution of $\\overline{X}_n$ becomes more concentrated around $\\mu$ as $n$ gets large.</span>\n",
    "\n",
    "<!-- <s>Sea $\\{X_i\\}_{i=1}^n$ un conjunto de $n$</s> -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teorema del Límite Central\n",
    "<span style=\"color:#0066CC\">The law of large numbers says that the distribution of $X_n$ piles up near $\\mu$. This isn’t enough to help us approximate probability statements about $X_n$. For this we need the central limit theorem.</span>\n",
    "\n",
    "<span style=\"color:#0066CC\">**The central limit theorem** (CLT) says that the sample mean $\\overline{X}_n=\\frac{1}{n}\\sum_{i=1}^n X_i$ has a distribution which is approximately Normal with mean $\\mu$ and variance $\\frac{\\sigma^2}{N}$.</span>\n",
    "\n",
    "<span style=\"color:#0066CC\">(Rewrote the therom in a simplier form)</span>\n",
    "\n",
    "Sean $X_1,...X_n$ v.a. iid de media $\\mu$ y varianza $\\sigma^2$, entonces\n",
    "$\\overline{X}_n=\\frac{1}{n}\\sum_{i=1}^n X_i$ cumple:\n",
    "\n",
    "$$ \\lim_{n \\to \\infty}P\\left( \\frac{\\overline{X}_n - \\mu}{\\sqrt{\\frac{\\sigma^2}{n}}} \\leq z\\right) = F_Z(z)  \\qquad Z \\sim \\cal{N}(0,1)$$\n",
    "\n",
    "Es decir que es posible aproximar la distribución de $\\overline{X}_n$ por ${\\cal{N}}(\\mu,\\frac{\\sigma^2}{n})$.\n",
    "\n",
    ":::{note}\n",
    "- <span style=\"color:#0066CC\">$X$ doesn't have to be normally distributed; it can be any distribution.</span>\n",
    "- <span style=\"color:#0066CC\">CLT is about the sample mean, not the random variable itself.</span>\n",
    ":::\n",
    "\n",
    "<span style=\"color:#0066CC\">Una aplicación muy importante del CLT consiste en determinar valores razonables de la media de la población μ. Temas como prueba de hipótesis, estimación, y muchos otros utilizan el CLT. Vamos a repasar esta teorema en alguna clase en el futuro.</span>\n",
    "\n",
    "<span style=\"color:#0066CC\">Fuente: Wasserman y WMMY</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}